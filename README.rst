新闻网页爬虫
=====================

	这是一个根据用户给定的url文件进行的多任务、多进程的新闻网页爬虫程序，并提供了一个简易的解析库parser.so
	
	(1).首先用户通过配置taskAttribute.txt文件设置任务个数和任务属性，该文件中的1:1，在":"左边的1表示设置的任务间隔，单位为h，该任务以1h为间隔，自动重启，
":"右边的1表示让该任务从开始时就执行，若为0则不执行此任务。

	(2).用户在urlListLoc.txt中设置任务的目录，该目录中存放该任务需要爬取的url，在urlList.txt文件中

	(3).用户在saveLocation.txt文件中设置各个爬取任务存放解析结果的目录

	(4).在每一个任务文件夹(如task1)下总共有三个文件，urlList.txt前面已经提及，addtionUrlList.txt中存放的是用户在该任务执行过程中想要添加的url列表，
runFlag.txt文件中存放的是该任务的运行标示，将其设置为0可以单独停止此任务，实现任务的分级管理。



运行说明:
	在程序运行前先安装python的库chardet，运行目录下的get-pip.py即可，然后配置好各个任务，最后运行Spider-master.py即可
